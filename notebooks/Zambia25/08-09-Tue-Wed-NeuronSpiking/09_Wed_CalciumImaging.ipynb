{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkipngenokoech/TReND-CaMinA-Zambia/blob/kip/notebooks/Zambia25/08-09-Tue-Wed-NeuronSpiking/09_Wed_CalciumImaging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img align=\"left\" width=\"300\" src=\"https://raw.githubusercontent.com/trendinafrica/TReND-CaMinA/main/images/CaMinA_logo.png\">\n",
        "\n",
        "# **TReND-CaMinA 2025: Calcium Imaging**\n",
        "\n",
        "**Content creator:** Artemis Koumoundourou\n",
        "\n",
        "**Acknowledgements:** Maxime Zimmermann for his support with Spikeling"
      ],
      "metadata": {
        "id": "BEQ4BwcIcxtc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **üîç 1. What is calcium imaging?**\n",
        "\n",
        "**Calcium imaging** is a technique used to visualize neuronal activity by measuring changes in calcium concentration within cells. It relies on **genetically encoded calcium indicators (GECIs)** ‚Äî fluorescent proteins that undergo a calcium-dependent conformational change, rendering them fluorescent in response to excitation light of a specific wavelength. When a neuron becomes active and fires an action potential, calcium enters the cell and binds to the indicator. By illuminating then the indicator with excitation light and capturing the resulting fluorescence, we can **indirectly measure neuronal activity**.\n",
        "\n",
        "<br>\n",
        "\n",
        "Unlike direct voltage recordings, calcium imaging captures the change in fluorescence of calcium-sensitive indicators as a proxy for neural activity.\n",
        "\n",
        "<br>\n",
        "\n",
        "Raw fluorescence values vary across neurons, experiments, or indicators. To make data comparable and interpretable, we normalize it using the **ŒîF/F** formula:\n",
        "\n",
        "<br>\n",
        "\n",
        "<center> $Œîùêπ/ùêπ =\\frac{ùêπ(ùë°)‚àíùêπ_0}{ùêπ_0}$ </center>\n",
        "\n",
        "<br>\n",
        "\n",
        "- $F(t)$: The fluorescence at each time point.\n",
        "- $F_{0}$: The baseline fluorescence ‚Äî typically measured during a quiet (non-spiking) period.\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "To better understand the relationship between neuronal activity and calcium signals, we will use Spikeling. By recording both membrane voltage and simulated calcium fluorescence from Spikeling under different conditions, we can explore how action potentials give rise to calcium transients and practice the same analysis techniques used in real calcium imaging experiments.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "**üìù Activity**\n",
        "\n",
        "- Set Spikeling to tonic spiking mode\n",
        "\n",
        "- Load and apply stimulus '10i_100msON_100msOFF' and record\n",
        "\n",
        "- Go to the Imaging function in the interface\n",
        "\n",
        "- Choose GCaMP6 as the fluorescent indicator\n",
        "\n",
        "- Calculate the ŒîF/F from the raw fluorescence data\n",
        "\n",
        "- Plot both signals on the same time axis:\n",
        "\n",
        "  - Top panel: Membrane voltage\n",
        "  - Bottom panel: ŒîF/F\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**üéØ Goal**\n",
        "\n",
        "To understand how calcium imaging can be used to indirectly measure neuronal activity and to learn how to process and visualize calcium imaging data using ŒîF/F normalization."
      ],
      "metadata": {
        "id": "M8OjY4zRctoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import the necessary libraries\n",
        "import ___                # Hint: for handling data tables\n",
        "import ___                # Hint: for plotting\n",
        "\n",
        "# Step 2: Upload and load your CSV file from local machine to DataFrame\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "TonicSpikingCa = pd.read_csv('___')\n",
        "\n",
        "# Optional: Preview your data to understand the structure\n"
      ],
      "metadata": {
        "id": "Up24JmljiYh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Detect and Align to Stimulus Onset\n",
        "\n",
        "# Find stimulus onset and offset times\n",
        "stim_onset = TonicSpikingCa[TonicSpikingCa['Stimulus (%)'] > 0]['___'].iloc[0]   # Hint: get the time of first nonzero stimulus\n",
        "stim_offset = TonicSpikingCa[TonicSpikingCa['Stimulus (%)'] > 0]['___'].iloc[-1]  # Hint: time of last nonzero stimulus\n",
        "\n",
        "stim_duration = ___ - ___   # Hint: calculate stimulus duration in ms\n",
        "\n",
        "# Define a time window around the stimulus\n",
        "window_start = stim_onset - ___    # Hint: start a bit before onset (e.g., 10 ms)\n",
        "window_end = stim_offset + ___     # Hint: go a bit beyond stimulus (e.g., 50 ms)\n",
        "\n",
        "\n",
        "# Step 4: Compute DF/F\n",
        "\n",
        "# Define baseline period and calculate F‚ÇÄ\n",
        "# Hint: use all time points *before* the stimulus\n",
        "baseline_window = TonicSpikingCa[TonicSpikingCa['Time (ms)'] < _____________]\n",
        "F0 = baseline_window['Spikeling Fluorescence']._________()  # is the mean\n",
        "\n",
        "# Formula: (F - F0) / F0\n",
        "TonicSpikingCa['DF/F'] = (TonicSpikingCa['Spikeling Fluorescence'] - ___) / ___\n",
        "\n",
        "\n",
        "# Step 5: Select a time window around the stimulus and filter data to keep only this window\n",
        "window_start = stim_onset - ___\n",
        "window_end = stim_offset + ___\n",
        "\n",
        "window_data = TonicSpikingCa[(TonicSpikingCa['___'] >= window_start) &\n",
        "                             (TonicSpikingCa['___'] <= window_end)]   # Hint: which column contains time?\n",
        "\n",
        "\n",
        "# Step 6: Align time axis so stimulus onset = 0\n",
        "window_data['Aligned Time (ms)'] = window_data['___'] - ___    # Hint: subtract stim_onset to shift time\n"
      ],
      "metadata": {
        "id": "ALPsUsQQbtQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Plotting Voltage and DF/F (Aligned to Stimulus Onset)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Subplot 1: Membrane Voltage (Vm)\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(window_data['Aligned Time (ms)'], window_data['___'], color='___')  # Hint: which column has Vm data? Pick a nice color like 'navy'\n",
        "plt.axvspan(___, ___, color='orange', alpha=0.2)  # Hint: where does stimulus start and end after alignment?\n",
        "plt.title(\"Membrane Voltage\")\n",
        "plt.ylabel(\"Vm (___)\")  # Hint: units\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Subplot 2: Fluorescence\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(window_data['Aligned Time (ms)'], window_data['___'], color='___')  # Hint: pick the fluorescence column, and a color like 'green'\n",
        "plt.axvspan(___, ___, color='orange', alpha=0.2)\n",
        "plt.title(\"Fluorescence Trace\")\n",
        "plt.xlabel(\"Time (ms)\")\n",
        "plt.ylabel(\"DF/F\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6942zUrDfQIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to see solution\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your data (replace filename with your actual file)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "TonicSpikingCa = pd.read_csv('calcium_500.csv')\n",
        "\n",
        "# Detect first stimulus onset: 0 ‚Üí 1 transition in the 'Stimulus' column\n",
        "stim_onset = TonicSpikingCa[TonicSpikingCa['Stimulus (%)'] > 0]['Time (ms)'].iloc[0]\n",
        "stim_offset = TonicSpikingCa[TonicSpikingCa['Stimulus (%)'] > 0]['Time (ms)'].iloc[-1]\n",
        "\n",
        "stim_duration = stim_offset - stim_onset\n",
        "\n",
        "\n",
        "# Select all fluorescence data before stimulus onset (starting from time 0)\n",
        "baseline_window = TonicSpikingCa[TonicSpikingCa['Time (ms)'] < stim_onset]\n",
        "\n",
        "# Compute F‚ÇÄ as the mean baseline fluorescence\n",
        "F0 = baseline_window['Spikeling Fluorescence'].mean()\n",
        "\n",
        "# Compute ŒîF/F\n",
        "TonicSpikingCa['DF/F'] = (TonicSpikingCa['Spikeling Fluorescence'] - F0) / F0\n",
        "\n",
        "\n",
        "#Define window around stimulus onset\n",
        "window_start = stim_onset - 50\n",
        "window_end = stim_offset + 100\n",
        "\n",
        "# Filter the data within that window\n",
        "window_data = TonicSpikingCa[(TonicSpikingCa['Time (ms)'] >= window_start) &\n",
        "                             (TonicSpikingCa['Time (ms)'] <= window_end)]\n",
        "\n",
        "# Align time so that stimulus onset = 0\n",
        "window_data['Aligned Time (ms)'] = window_data['Time (ms)'] - stim_onset\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Vm trace\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(window_data['Aligned Time (ms)'], window_data['Spikeling Vm (mV)'], color='navy')\n",
        "plt.title(\"Membrane Voltage\")\n",
        "plt.ylabel(\"Vm (mV)\")\n",
        "plt.axvspan(0, stim_duration, color='orange', alpha=0.2)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# Fluorescence trace\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(window_data['Aligned Time (ms)'], window_data['DF/F'], color='green')\n",
        "plt.axvspan(0, stim_duration, color='orange', alpha=0.2)\n",
        "plt.title(\"Fluorescence Trace\")\n",
        "plt.xlabel(\"Time (ms)\")\n",
        "plt.ylabel(\"DF/F\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ppfa0aJycxVG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üß† Questions for Discussion**\n",
        "\n",
        "- What do you observe about the shape of the calcium signal?\n",
        "- Does it rise immediately with each spike? Or is there a delay and slower decay?\n",
        "- What happens to the calcium trace when spikes are close together?\n",
        "- What might be some advantages and limitations of calcium imaging compared to direct voltage recordings?"
      ],
      "metadata": {
        "id": "CJwjjhobfhNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üîç 2. How accurately does calcium imaging reflect spike timing?**\n",
        "\n",
        "**Calcium imaging** is a powerful method for visualizing neural activity, but it captures a **slower, indirect signal** compared to the rapid voltage changes of action potentials. The calcium signal‚Äîmeasured as ŒîF/F‚Äîrises and decays over hundreds of milliseconds, which can blur the precise timing of individual spikes.\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**üìù Activity**\n",
        "\n",
        "- Set Spikeling to tonic spiking mode\n",
        "- Record both membrane voltage and fluorescence (on GCaMP6)\n",
        "- Use a 500 ms OFF / 500 ms ON stimulus, repeat at least 5‚Äì10 times\n",
        "- Compute spike number for each trial and the average ŒîF/F over all trials\n",
        "- Plot the raster of each trial over the average ŒîF/F trace\n",
        "- Repeat for tonic bursting neuron\n",
        "\n",
        "<br>\n",
        "\n",
        "**üéØ Goal**\n",
        "\n",
        "To understand the temporal limitations of calcium imaging by comparing real spike times to the slower calcium signal."
      ],
      "metadata": {
        "id": "cvtPgEuAfVTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import the necessary libraries\n",
        "import ___                # Hint: for handling data tables\n",
        "import ___                # Hint: for numerical operations\n",
        "import ___                # Hint: for plotting\n",
        "\n",
        "\n",
        "# Step 2: Upload and load your CSV file from local machine to a DataFrame\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "TS_Ca_x10 = pd.read_csv('___')\n",
        "\n",
        "# Optional: Preview your data to understand the structure\n"
      ],
      "metadata": {
        "id": "P3JPmg1-Tnx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Detect Stimulus Onsets & Offsets\n",
        "# Find indices where stimulus goes from 0 to positive (stimulus ON)\n",
        "onsets = TS_Ca_x10.index[(TS_Ca_x10['Stimulus (%)'].shift(1) == 0) & (TS_Ca_x10['Stimulus (%)'] > 0)].tolist()\n",
        "\n",
        "# Find indices where stimulus goes from positive to 0 (stimulus OFF)\n",
        "offsets = TS_Ca_x10.index[(TS_Ca_x10['Stimulus (%)'].shift(1) > 0) & (TS_Ca_x10['Stimulus (%)'] == 0)].tolist()\n",
        "\n",
        "\n",
        "# Step 4: Segment Trials\n",
        "# Define your sampling interval in ms per sample (e.g., 0.1 ms/sample)\n",
        "sampling_interval = _______  # e.g., 0.1\n",
        "\n",
        "# Define trial duration in number of samples (trial length (ms) / sampling interval)\n",
        "trial_duration_samples = _______\n",
        "\n",
        "voltage_trials = []\n",
        "fluorescence_trials = []\n",
        "\n",
        "for ______ in ______:  # Loop over all stimulus onsets (list of indices)\n",
        "    start = ______     # Define trial start index (current onset)\n",
        "    end = ______ + ______  # Define trial end index (start + trial duration in samples)\n",
        "\n",
        "    # Make sure indices are valid to avoid indexing errors\n",
        "    if start >= 0 and end < len(______):  # Check within data length\n",
        "        voltage_trials.append(______[______].iloc[start:end].values)  # Extract voltage trial\n",
        "        fluorescence_trials.append(______[______].iloc[start:end].values)  # Extract fluorescence trial\n",
        "\n",
        "\n",
        "# Create time axis in ms for plotting\n",
        "time_axis = np.arange(trial_duration_samples) * sampling_interval\n"
      ],
      "metadata": {
        "id": "ZBSXlfhvUOlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Detect Spikes in Each Trial\n",
        "def detect_spike_times(voltage, threshold=_______):\n",
        "    spike_times = np.where(voltage > threshold)[0]\n",
        "    return spike_times\n",
        "\n",
        "# Detect spikes per trial\n",
        "raster_spikes = [detect_spike_times(trial) for trial in voltage_trials]\n",
        "\n",
        "\n",
        "# Step 6: Compute DF/F for Each Trial\n",
        "# Define baseline duration before stimulus onset (in ms)\n",
        "baseline_duration_ms = _______  # e.g., 300\n",
        "\n",
        "# Calculate how many samples this corresponds to\n",
        "pre_stim_samples = int(baseline_duration_ms / _______)\n",
        "\n",
        "dff_trials = []\n",
        "for trace in fluorescence_trials:\n",
        "    # Calculate baseline fluorescence F0 as mean of baseline window\n",
        "    f0 = np.mean(trace[:_______])\n",
        "\n",
        "    # Compute DF/F normalized fluorescence change\n",
        "    dff = (trace - f0) / _______\n",
        "    dff_trials.append(dff)\n"
      ],
      "metadata": {
        "id": "FQRoHSxGV7PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Plot Raster and Average DF/F\n",
        "\n",
        "plt.figure(figsize=(_______, _______))  # Hint: Choose figure size (width, height)\n",
        "\n",
        "# Raster plot: each vertical line is a spike for a trial\n",
        "plt.subplot(_______, _______, _______)  # Hint: Use subplot(rows, cols, index)\n",
        "for i, spikes in enumerate(raster_spikes):\n",
        "    plt.vlines(time_axis[spikes], i + _______, i + _______, color='_______')\n",
        "    # Hint: Set vertical line start/end to create spaced lines per trial, choose color\n",
        "\n",
        "plt.title(\"Raster Plot of Spikes\")\n",
        "plt.ylabel(\"_______\")  # Hint: Label y-axis, e.g. 'Trial'\n",
        "plt.xlim(0, time_axis[_______])  # Hint: Set x-axis limits to span time_axis range\n",
        "plt.grid(_______)  # Hint: Enable grid with True or False\n",
        "\n",
        "# Average DF/F across trials\n",
        "plt.subplot(_______, _______, _______)  # Hint: Next subplot for average DF/F\n",
        "\n",
        "mean_dff = np.___(dff_trials, axis=_______)  # Hint: Average across trials (axis=0 or 1)\n",
        "plt.plot(time_axis, mean_dff, color='_______')  # Hint: Choose color for DF/F trace\n",
        "\n",
        "plt.title(\"Average DF/F Across Trials\")\n",
        "plt.xlabel(\"_______\")  # Hint: Label x-axis, e.g. 'Time (ms)'\n",
        "plt.ylabel(\"_______\")  # Hint: Label y-axis, e.g. 'DF/F'\n",
        "plt.xlim(0, time_axis[_______])  # Hint: Match x-axis limits to time_axis\n",
        "plt.grid(_______)  # Hint: Enable grid (True/False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3_xGT8ihXMy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to see solution\n",
        "\n",
        "# Step 1: Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Import the CSV File\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "data = pd.read_csv(\"TS_Ca_500_10x.csv\")\n",
        "\n",
        "# Step 3: Detect Stimulus Onsets & Offsets\n",
        "onsets = data.index[(data['Stimulus (%)'].shift(1) == 0) & (data['Stimulus (%)'] > 0)].tolist()\n",
        "offsets = data.index[(data['Stimulus (%)'].shift(1) > 0) & (data['Stimulus (%)'] == 0)].tolist()\n",
        "\n",
        "# Step 4: Segment Trials\n",
        "sampling_interval = 0.1  # ms per sample\n",
        "trial_duration_samples = 5000  # 500 ms * 10 = 5000 samples if 0.1 ms per sample\n",
        "\n",
        "voltage_trials = []\n",
        "fluorescence_trials = []\n",
        "\n",
        "for onset in onsets:\n",
        "    start = onset\n",
        "    end = onset + trial_duration_samples\n",
        "    if start >= 0 and end < len(data):\n",
        "        voltage_trials.append(data['Spikeling Vm (mV)'].iloc[start:end].values)\n",
        "        fluorescence_trials.append(data['Spikeling Fluorescence'].iloc[start:end].values)\n",
        "\n",
        "time_axis = np.arange(trial_duration_samples) * sampling_interval\n",
        "\n",
        "# Step 5: Detect Spikes in Each Trial\n",
        "def detect_spike_times(voltage, threshold=-20):\n",
        "    spike_times = np.where(voltage > threshold)[0]\n",
        "    return spike_times\n",
        "\n",
        "raster_spikes = [detect_spike_times(trial) for trial in voltage_trials]\n",
        "\n",
        "# Step 6: Compute DF/F for Each Trial\n",
        "pre_stim_samples = int(300 / sampling_interval)  # 300 ms baseline\n",
        "\n",
        "dff_trials = []\n",
        "for trace in fluorescence_trials:\n",
        "    f0 = np.mean(trace[:pre_stim_samples])\n",
        "    dff = (trace - f0) / f0\n",
        "    dff_trials.append(dff)\n",
        "\n",
        "# Step 7: Plot Raster and Average DF/F\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Raster Plot\n",
        "plt.subplot(2, 1, 1)\n",
        "for i, spikes in enumerate(raster_spikes):\n",
        "    plt.vlines(time_axis[spikes], i + 0.5, i + 1.5, color='black')\n",
        "plt.title(\"Raster Plot of Spikes\")\n",
        "plt.ylabel(\"Trial\")\n",
        "plt.xlim(0, time_axis[-1])\n",
        "\n",
        "# Average DF/F\n",
        "plt.subplot(2, 1, 2)\n",
        "mean_dff = np.mean(dff_trials, axis=0)\n",
        "plt.plot(time_axis, mean_dff, color='green')\n",
        "plt.title(\"Average DF/F Across Trials\")\n",
        "plt.xlabel(\"Time (ms)\")\n",
        "plt.ylabel(\"DF/F\")\n",
        "plt.xlim(0, time_axis[-1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eW-Td1QESVy0",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "E3D65rHYO9Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Repeat for Tonic Bursting neuron\n",
        "\n",
        "# Step 1: Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Import the CSV File\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "data = pd.read_csv(\"TB_Ca_500_10x.csv\")\n",
        "\n",
        "# Step 3: Detect Stimulus Onsets & Offsets\n",
        "onsets = data.index[(data['Stimulus (%)'].shift(1) == 0) & (data['Stimulus (%)'] > 0)].tolist()\n",
        "offsets = data.index[(data['Stimulus (%)'].shift(1) > 0) & (data['Stimulus (%)'] == 0)].tolist()\n",
        "\n",
        "# Step 4: Segment Trials\n",
        "sampling_interval = 0.1  # ms per sample\n",
        "trial_duration_samples = 5000  # 500 ms * 10 = 5000 samples if 0.1 ms per sample\n",
        "\n",
        "voltage_trials = []\n",
        "fluorescence_trials = []\n",
        "\n",
        "for onset in onsets:\n",
        "    start = onset\n",
        "    end = onset + trial_duration_samples\n",
        "    if start >= 0 and end < len(data):\n",
        "        voltage_trials.append(data['Spikeling Vm (mV)'].iloc[start:end].values)\n",
        "        fluorescence_trials.append(data['Spikeling Fluorescence'].iloc[start:end].values)\n",
        "\n",
        "time_axis = np.arange(trial_duration_samples) * sampling_interval\n",
        "\n",
        "# Step 5: Detect Spikes in Each Trial\n",
        "def detect_spike_times(voltage, threshold=-20):\n",
        "    spike_times = np.where(voltage > threshold)[0]\n",
        "    return spike_times\n",
        "\n",
        "raster_spikes = [detect_spike_times(trial) for trial in voltage_trials]\n",
        "\n",
        "# Step 6: Compute DF/F for Each Trial\n",
        "pre_stim_samples = int(300 / sampling_interval)  # 300 ms baseline\n",
        "\n",
        "dff_trials = []\n",
        "for trace in fluorescence_trials:\n",
        "    f0 = np.mean(trace[:pre_stim_samples])\n",
        "    dff = (trace - f0) / f0\n",
        "    dff_trials.append(dff)\n",
        "\n",
        "# Step 7: Plot Raster and Average DF/F\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Raster Plot\n",
        "plt.subplot(2, 1, 1)\n",
        "for i, spikes in enumerate(raster_spikes):\n",
        "    plt.vlines(time_axis[spikes], i + 0.5, i + 1.5, color='black')\n",
        "plt.title(\"Raster Plot of Spikes\")\n",
        "plt.ylabel(\"Trial\")\n",
        "plt.xlim(0, time_axis[-1])\n",
        "\n",
        "# Average DF/F\n",
        "plt.subplot(2, 1, 2)\n",
        "mean_dff = np.mean(dff_trials, axis=0)\n",
        "plt.plot(time_axis, mean_dff, color='green')\n",
        "plt.title(\"Average DF/F Across Trials\")\n",
        "plt.xlabel(\"Time (ms)\")\n",
        "plt.ylabel(\"DF/F\")\n",
        "plt.xlim(0, time_axis[-1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UM5gb1zdsF-3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**üß† Questions for Discussion**\n",
        "- Do the calcium transients start exactly when spikes occur?\n",
        "- What do you notice about the rise time and decay time?\n",
        "- Can you always tell how many spikes there were from the calcium trace?\n",
        "\n"
      ],
      "metadata": {
        "id": "iOMvaOxNgQOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **üîç 3. How well does ŒîF/F reflect firing rate?**\n",
        "\n",
        "Calcium imaging provides an **indirect estimate of firing rate**, with ŒîF/F signals reflecting the buildup and decay of intracellular calcium triggered by spikes. While this signal smooths over rapid changes, it still **correlates with spike rate over time**.\n",
        "\n",
        "<br>\n",
        "\n",
        "**üìù Activity**\n",
        "\n",
        "- Create binned spike counts from the voltage trace (e.g., using 50 ms bins).\n",
        "\n",
        "- Compute mean ŒîF/F in the same bins.\n",
        "\n",
        "- Plot a scatter plot of ŒîF/F vs spike count across time bins.\n",
        "\n",
        "- Fit a linear or nonlinear model.\n",
        "\n",
        "<br>\n",
        "\n",
        "**üéØ Goal**\n",
        "\n",
        "To understand how ŒîF/F signals relate to the underlying neuronal firing rate. Learn how to quantify and visualize this relationship by comparing binned spike counts with average fluorescence, and reflect on the reliability and limitations of calcium imaging as a proxy for spiking."
      ],
      "metadata": {
        "id": "FRyXpeN9surx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# PARAMETERS\n",
        "bin_size_ms = _____  # e.g., 50 ms bin size for time windows\n",
        "sampling_interval = _____  # in ms per sample\n",
        "samples_per_bin = int(_______ / ________)  # convert bin size to number of samples\n",
        "\n",
        "# Step 1: Spike Detection\n",
        "threshold = _____\n",
        "spike_indices = np.where(_______ > _______)[0]  # Hint: voltage trace > threshold\n",
        "\n",
        "# Optional: Remove spikes within refractory period (e.g., < 5 samples apart)\n",
        "spike_indices = spike_indices[np.diff(np.concatenate(([____], spike_indices))) > ____]"
      ],
      "metadata": {
        "id": "zpbjDFgB5duy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Bin spike counts\n",
        "n_bins = len(______) // ________  # total number of bins\n",
        "binned_spike_counts = np.zeros(_______)\n",
        "\n",
        "# Loop over detected spikes\n",
        "for i in spike_indices:\n",
        "    bin_idx = i // _______\n",
        "    if bin_idx < _______:\n",
        "        binned_spike_counts[bin_idx] += _____\n",
        "\n",
        "# Step 3: Bin DF/F (average calcium signal in each bin)\n",
        "binned_dff = np.array([\n",
        "    ______[i * samples_per_bin : (i+1) * samples_per_bin].______()  # Hint: mean\n",
        "    for i in range(n_bins)\n",
        "])"
      ],
      "metadata": {
        "id": "ZypDmXPF4d75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Scatter Plot of Binned ŒîF/F vs Spike Count\n",
        "plt.figure(figsize=(__, __))  # Hint: try (6, 4)\n",
        "\n",
        "plt.scatter(______, ______, color='green', alpha=0.6)  # Hint: spike counts, dff\n",
        "\n",
        "plt.xlabel(\"Spike Count per Bin (_____ ms)\")\n",
        "plt.ylabel(\"Mean DF/F\")\n",
        "plt.title(\"Spike Rate vs. Calcium Signal\")\n",
        "\n",
        "# Step 5: Fit Linear Model\n",
        "X = binned_spike_counts.reshape(-1, ____)  # Reshape to column vector\n",
        "y = binned_dff\n",
        "model = LinearRegression()._____(X, y)\n",
        "\n",
        "# Predict fitted line\n",
        "x_fit = np.linspace(0, X._____(), 100)  # Hint: use max spike count\n",
        "y_fit = model._______(x_fit.reshape(-1, 1))  # Predict y values\n",
        "\n",
        "plt.plot(______, ______, color='black', linestyle='--', label='Linear Fit')  # Fit line\n",
        "\n",
        "plt._______()  # Add legend\n",
        "plt.tight_layout()\n",
        "plt._______()  # Show plot\n",
        "\n",
        "# Step 6: Correlation\n",
        "corr = np.________(binned_spike_counts, binned_dff)[0, 1]  # Hint: correlation matrix\n",
        "print(f\"Correlation between spike rate and DF/F: r = {corr:.2f}\")"
      ],
      "metadata": {
        "id": "_jmvNgWI5ydY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to see solution\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "vm = data['Spikeling Vm (mV)'].values\n",
        "dff = data['Spikeling Fluorescence'].values\n",
        "\n",
        "# PARAMETERS\n",
        "bin_size_ms = 50  # size of time bins\n",
        "sampling_interval = 0.1  # in ms\n",
        "samples_per_bin = int(bin_size_ms / sampling_interval)\n",
        "\n",
        "# 1. Detect spikes (threshold crossing)\n",
        "threshold = -20  # Adjust as needed\n",
        "spike_indices = np.where(vm > threshold)[0]\n",
        "spike_indices = spike_indices[np.diff(np.concatenate(([0], spike_indices))) > 5]  # refractory filter\n",
        "\n",
        "# 2. Bin spike counts\n",
        "n_bins = len(vm) // samples_per_bin\n",
        "binned_spike_counts = np.zeros(n_bins)\n",
        "for i in spike_indices:\n",
        "    bin_idx = i // samples_per_bin\n",
        "    if bin_idx < n_bins:\n",
        "        binned_spike_counts[bin_idx] += 1\n",
        "\n",
        "# 3. Bin DF/F\n",
        "binned_dff = np.array([\n",
        "    dff[i * samples_per_bin : (i+1) * samples_per_bin].mean()\n",
        "    for i in range(n_bins)\n",
        "])\n",
        "\n",
        "# 4. Scatter plot: DF/F vs Spike Count\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(binned_spike_counts, binned_dff, color='green', alpha=0.6)\n",
        "plt.xlabel(\"Spike Count per Bin (50 ms)\")\n",
        "plt.ylabel(\"Mean DF/F\")\n",
        "plt.title(\"Spike Rate vs. Calcium Signal\")\n",
        "\n",
        "# 5. Fit linear model\n",
        "X = binned_spike_counts.reshape(-1, 1)\n",
        "y = binned_dff\n",
        "model = LinearRegression().fit(X, y)\n",
        "x_fit = np.linspace(0, X.max(), 100)\n",
        "y_fit = model.predict(x_fit.reshape(-1, 1))\n",
        "plt.plot(x_fit, y_fit, color='black', linestyle='--', label='Linear Fit')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print correlation\n",
        "corr = np.corrcoef(binned_spike_counts, binned_dff)[0, 1]\n",
        "print(f\"Correlation between spike rate and DF/F: r = {corr:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LyG3-OQMI3kB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üß† Questions for Discussion**\n",
        "- How strong is the relationship between ŒîF/F and spike count in your plot?\n",
        "- How does bin size affect your results?\n",
        "- Would this method work equally well for all types of neurons or firing patterns?\n",
        "- If you wanted to recover more detailed information (e.g., exact spike times), what additional tools or strategies could you use?\n"
      ],
      "metadata": {
        "id": "V8okneCc26sS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **üîç 4. How do neurons in a population respond to different stimuli?**\n",
        "\n",
        "Neurons within a population often respond differently to various stimuli, each showing selectivity for certain features‚Äîthis is the foundation of **tuning curves**. By analyzing ŒîF/F calcium signals in a defined response window after stimulus onset, we can determine how strongly each neuron responds to each stimulus.\n",
        "\n",
        "<br>\n",
        "\n",
        "**üìù Activity**\n",
        "\n",
        "- You are provided with a dataset (population_timeseries.csv) that contains:\n",
        "\n",
        "  - Time-series ŒîF/F data from several neurons\n",
        "\n",
        "  - Trial and stimulus information\n",
        "\n",
        "Each trial contains a stimulus that starts at frame index 30. Your task is to:\n",
        "\n",
        "- Focus on the response window:\n",
        "Extract the calcium responses from a short window after stimulus onset (e.g., frames 30‚Äì40).\n",
        "\n",
        "- Compute the mean ŒîF/F per neuron, per stimulus, per trial in that window.\n",
        "\n",
        "- Average across trials to find each neuron's mean response per stimulus (i.e., the tuning curve).\n",
        "\n",
        "- Plot tuning curves for a few example neurons (e.g., the first 5).\n",
        "\n",
        "<br>\n",
        "\n",
        "**üéØ Goal**\n",
        "\n",
        "To learn how to process ŒîF/F data from multiple neurons across multiple trials and stimuli, compute stimulus-specific responses, and plot neuron tuning curves.\n",
        "This gives insight into stimulus selectivity at the single-neuron and population levels.\n"
      ],
      "metadata": {
        "id": "qzK3Pgq_o_1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load CSV file from your computer\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "LbH_6sTGQpgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the time-series DF/F data into a DataFrame\n",
        "population = pd.read_csv(\"_______________________\")  # Hint: Replace with your uploaded file name\n",
        "\n",
        "# Step 2: Set parameters for stimulus window\n",
        "stim_onset = _____        # Hint: Frame index when stimulus begins\n",
        "window = _____            # Hint: Number of frames to average after stimulus\n",
        "\n",
        "# Step 3: Select post-stimulus window from the full dataset\n",
        "post_stim_df = population[\n",
        "    (population['_____'] >= stim_onset) &\n",
        "    (population['_____'] < stim_onset + window)\n",
        "]  # Hint: Use the 'time' column to slice frames after stimulus onset"
      ],
      "metadata": {
        "id": "OOXBB_C_Q2YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Compute the mean DF/F per neuron, stimulus, and trial\n",
        "# Group by neuron, stimulus, and trial\n",
        "grouped = post_stim_df.groupby(['___', '___', '___']) # Hint: group by neuron, stimulus, and trial\n",
        "\n",
        "# Compute the average DF/F for each group\n",
        "mean_responses = grouped['___'].___().reset_index()\n",
        "\n",
        "\n",
        "# Step 5: Compute tuning curve by averaging over trials\n",
        "# Group the mean responses by neuron and stimulus\n",
        "grouped_tuning = ___.groupby(['___', '___'])\n",
        "\n",
        "# Compute the average FF/F across trials for each neuron-stimulus pair\n",
        "tuning_curves = grouped_tuning['___'].___().reset_index()\n",
        "\n",
        "\n",
        "# Step 6: Convert to matrix format for plotting\n",
        "tuning_matrix = tuning_curves.pivot(\n",
        "    index='______', columns='________', values='___'  # Hint: Neurons as rows, stimuli as columns\n",
        ")"
      ],
      "metadata": {
        "id": "l2xuH4KDRBbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Plot tuning curves for the first few neurons\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "for neuron in tuning_matrix.index[:___]:  # Hint: plot e.g., first 5 neurons\n",
        "    plt.plot(\n",
        "        tuning_matrix.columns,\n",
        "        tuning_matrix.loc[______],         # Hint: retrieve row for this neuron\n",
        "        marker='o',\n",
        "        label=neuron\n",
        "    )\n",
        "\n",
        "plt.title('Tuning Curves')\n",
        "plt.xlabel('_________')  # Hint: What are the x-axis values?\n",
        "plt.ylabel('__________')  # Hint: y-axis shows averaged calcium response\n",
        "plt.legend()\n",
        "plt._______()  # Hint: Show the plot"
      ],
      "metadata": {
        "id": "m2kjCVQ2SWKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "üí¨ Documentation for [`pd.pivot`](https://pandas.pydata.org/docs/reference/api/pandas.pivot.html#pandas.pivot).\n",
        "\n",
        "It reshapes a DataFrame by turning unique values from one column into new columns, using another column for row labels and a third column to fill the cell values.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kLHWhFghS_gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to see solution\n",
        "\n",
        "# Step 1: Load time-series DF/F to Dataframe\n",
        "population = pd.read_csv(\"population_timeseries.csv\")\n",
        "\n",
        "\n",
        "# Step 2: Set parameters\n",
        "stim_onset = 30       # stimulus start frame index\n",
        "window = 10           # number of frames after stimulus onset to average over\n",
        "\n",
        "\n",
        "# Step 3: Select post-stimulus window data\n",
        "post_stim_df = population[(population['time'] >= stim_onset) & (population['time'] < stim_onset + window)]\n",
        "\n",
        "\n",
        "# Step 4: Compute mean DF/F per trial, stimulus, neuron in this window\n",
        "# Group by neuron, stimulus, and trial\n",
        "grouped = post_stim_df.groupby(['neuron', 'stimulus', 'trial'])\n",
        "\n",
        "# Compute the average DF/F for each group\n",
        "mean_responses = grouped['dff'].mean().reset_index()\n",
        "\n",
        "\n",
        "# Step 5: Compute tuning curve by averaging over trials\n",
        "# Group the mean responses by neuron and stimulus\n",
        "grouped_tuning = mean_responses.groupby(['neuron', 'stimulus'])\n",
        "\n",
        "# Compute the average DF/F across trials for each neuron-stimulus pair\n",
        "tuning_curves = grouped_tuning['dff'].mean().reset_index()\n",
        "\n",
        "\n",
        "# Step 6: Pivot to matrix form for plotting (neurons √ó stimuli)\n",
        "tuning_matrix = tuning_curves.pivot(index='neuron', columns='stimulus', values='dff')\n",
        "\n",
        "\n",
        "# Step 7: Plot tuning curve example for first 5 neurons\n",
        "plt.figure(figsize=(10,6))\n",
        "for neuron in tuning_matrix.index[:5]:\n",
        "    plt.plot(tuning_matrix.columns, tuning_matrix.loc[neuron], marker='o', label=neuron)\n",
        "\n",
        "plt.title('Tuning Curves')\n",
        "plt.xlabel('Stimulus')\n",
        "plt.ylabel('Mean DF/F')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e0xGXG0bdoAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Instead of plotting individual curves, which can become cluttered and hard to compare, a heatmap allows you to see patterns across the entire population at a glance.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "irRe2MtbXOnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Compute mean and std over trials\n",
        "# Group by neuron and stimulus to capture variability across trials\n",
        "grouped_stats = mean_responses.groupby(['_______', '________'])  # Hint: Which two columns define a condition?\n",
        "\n",
        "# Calculate both mean and standard deviation of ŒîF/F across trials\n",
        "tuning_stats = grouped_stats['___'].agg(['____', '___']).reset_index()\n",
        "# Hint: compute mean and std of the 'dff' signal\n",
        "\n",
        "# Step 9: Pivot to matrix form (neurons √ó stimuli)\n",
        "mean_matrix = tuning_stats.pivot(\n",
        "    index='_______',      # Hint: One row per neuron\n",
        "    columns='________',   # Hint: One column per stimulus\n",
        "    values='____'         # Hint: Use the average value\n",
        ")\n",
        "\n",
        "std_matrix = tuning_stats.pivot(\n",
        "    index='_______',\n",
        "    columns='________',\n",
        "    values='____'         # Hint: Use the standard deviation\n",
        ")\n",
        "\n",
        "# Step 10: Plot heatmap of mean tuning curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(mean_matrix, cmap='________', cbar_kws={'label': '___________'})\n",
        "# Hint 1: Try colormaps like 'viridis', 'magma', 'coolwarm'\n",
        "# Hint 2: What should the colorbar label show? (e.g., Mean ŒîF/F)"
      ],
      "metadata": {
        "id": "jeNvJerxbRuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to see solution\n",
        "\n",
        "# Step 8: Compute mean and std over trials\n",
        "# Group by neuron and stimulus\n",
        "grouped_stats = mean_responses.groupby(['neuron', 'stimulus'])\n",
        "\n",
        "# Calculate both mean and standard deviation of ŒîF/F across trials\n",
        "tuning_stats = grouped_stats['dff'].agg(['mean', 'std']).reset_index()\n",
        "\n",
        "# Step 9: Pivot to matrix form\n",
        "mean_matrix = tuning_stats.pivot(index='neuron', columns='stimulus', values='mean')\n",
        "std_matrix = tuning_stats.pivot(index='neuron', columns='stimulus', values='std')\n",
        "\n",
        "# Step 10: Plot heatmap of mean tuning curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(mean_matrix, cmap='viridis', cbar_kws={'label': 'Mean ŒîF/F'})"
      ],
      "metadata": {
        "id": "kt3Drz2CNb0d",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üß† Questions for Discussion**\n",
        "- Do different neurons respond to different stimuli?\n",
        "- Are some neurons more selective than others?\n",
        "- What do these differences tell you about how information is encoded across a neural population?\n"
      ],
      "metadata": {
        "id": "YPxQVbRLcTUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **üîç 5. How do populations of neurons encode information?**\n",
        "\n",
        "Neural populations encode information not just through individual firing rates or tuning, but through **patterns of activity across many neurons** - a principle known as **population coding**. Each stimulus evokes a distinct **population vector**: a combination of responses from multiple neurons that, together, uniquely represent that input.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**üìù Activity**\n",
        "- Extract the post-stimulus window (e.g., 10 frames after stimulus onset at time index 30).\n",
        "\n",
        "- Compute the mean ŒîF/F per neuron per trial during this window.\n",
        "This gives you one value per neuron, per trial ‚Äî forming a population activity vector.\n",
        "\n",
        "- Create a matrix where:\n",
        "\n",
        "  - Each row = one trial\n",
        "\n",
        "  - Each column = one neuron\n",
        "\n",
        "  - Each cell = that neuron's mean ŒîF/F during that trial\n",
        "\n",
        "- Calculate pairwise cosine distances between trials.\n",
        "\n",
        "  - Cosine distance reflects the angle between population vectors (1 = completely dissimilar, 0 = identical pattern of activation).\n",
        "\n",
        "  - This helps assess whether trials from the same stimulus group together.\n",
        "\n",
        "- Visualize the distance matrix as a heatmap.\n",
        "\n",
        "<br>\n",
        "\n",
        "**üéØ Goal**\n",
        "\n",
        "To explore how neural populations encode information by comparing entire response patterns (population vectors) across trials ‚Äî not just individual neuron tuning. This gives insight into population coding: how combinations of neurons together represent different stimuli."
      ],
      "metadata": {
        "id": "aTfRFQO-c5e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load time-series ŒîF/F data\n",
        "df = pd.read_csv(\"________________________\")  # Hint: path to CSV file containing 'time', 'neuron', 'stimulus', 'trial', 'dff'"
      ],
      "metadata": {
        "id": "qiKN1cZx2LhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set parameters\n",
        "stim_onset = _____         # Hint: Which frame does the stimulus begin?\n",
        "window = _____             # Hint: Over how many frames do you want to average post-stimulus activity?\n",
        "\n",
        "# Step 2: Extract post-stimulus window\n",
        "post_stim = df[(df[\"time\"] >= _________) & (df[\"time\"] < __________)]\n",
        "# Hint: Select only the data from stimulus onset up to onset + window\n",
        "\n",
        "# Step 3: Compute mean ŒîF/F per neuron per trial\n",
        "grouped_dff = post_stim.groupby([\"_______\", \"________\", \"________\"])  # Hint: Which 3 columns define each unique condition?\n",
        "\n",
        "mean_dff = grouped_dff[\"____\"].mean().reset_index()  # Hint: Compute the mean of the 'dff' column\n",
        "\n",
        "# Step 4: Pivot into population vectors: rows = trials, columns = neurons\n",
        "population_df = mean_dff.pivot_table(\n",
        "    index=[\"_____\", \"________\"],   # Hint: Each row should represent one trial + stimulus\n",
        "    columns=\"_______\",             # Hint: Each column corresponds to a neuron\n",
        "    values=\"____\"                  # Hint: Fill the table with mean ŒîF/F values\n",
        ")\n",
        "\n",
        "# Step 5: Compute pairwise cosine distances between population vectors\n",
        "cosine_dist = pairwise_distances(population_df, metric='________')  # Hint: Use 'cosine' for angle-based dissimilarity\n"
      ],
      "metadata": {
        "id": "lyoak67o2bke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Plot the distance matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.___(cosine_dist, xticklabels=False, yticklabels=False, cmap='________')  # Hint: Heatmap; choose a palette eg. 'viridis', 'magma', etc.\n",
        "plt.title(\"Pairwise Cosine Distances Between Population Vectors (Trials)\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.ylabel(\"Trial\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cdrXtEsF2roV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "B0ZJhIuytGin"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(sns)"
      ],
      "metadata": {
        "id": "bxabo0ALtPE9",
        "outputId": "88c83470-1dbf-4e0d-ca8f-d51c3973b1c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on package seaborn:\n",
            "\n",
            "NAME\n",
            "    seaborn - # Import seaborn objects\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    _base\n",
            "    _compat\n",
            "    _core (package)\n",
            "    _docstrings\n",
            "    _marks (package)\n",
            "    _statistics\n",
            "    _stats (package)\n",
            "    _testing\n",
            "    algorithms\n",
            "    axisgrid\n",
            "    categorical\n",
            "    cm\n",
            "    colors (package)\n",
            "    distributions\n",
            "    external (package)\n",
            "    matrix\n",
            "    miscplot\n",
            "    objects\n",
            "    palettes\n",
            "    rcmod\n",
            "    regression\n",
            "    relational\n",
            "    utils\n",
            "    widgets\n",
            "\n",
            "DATA\n",
            "    crayons = {'Almond': '#EFDECD', 'Antique Brass': '#CD9575', 'Apricot':...\n",
            "    xkcd_rgb = {'acid green': '#8ffe09', 'adobe': '#bd6c48', 'algae': '#54...\n",
            "\n",
            "VERSION\n",
            "    0.13.2\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.11/dist-packages/seaborn/__init__.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(sns)"
      ],
      "metadata": {
        "id": "jrJLEjsVtqqN",
        "outputId": "2e54a781-279d-4ad9-9365-54d993300e62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['FacetGrid',\n",
              " 'JointGrid',\n",
              " 'PairGrid',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " '_base',\n",
              " '_compat',\n",
              " '_core',\n",
              " '_docstrings',\n",
              " '_orig_rc_params',\n",
              " '_statistics',\n",
              " '_stats',\n",
              " 'algorithms',\n",
              " 'axes_style',\n",
              " 'axisgrid',\n",
              " 'barplot',\n",
              " 'blend_palette',\n",
              " 'boxenplot',\n",
              " 'boxplot',\n",
              " 'categorical',\n",
              " 'catplot',\n",
              " 'choose_colorbrewer_palette',\n",
              " 'choose_cubehelix_palette',\n",
              " 'choose_dark_palette',\n",
              " 'choose_diverging_palette',\n",
              " 'choose_light_palette',\n",
              " 'clustermap',\n",
              " 'cm',\n",
              " 'color_palette',\n",
              " 'colors',\n",
              " 'countplot',\n",
              " 'crayon_palette',\n",
              " 'crayons',\n",
              " 'cubehelix_palette',\n",
              " 'dark_palette',\n",
              " 'desaturate',\n",
              " 'despine',\n",
              " 'displot',\n",
              " 'distplot',\n",
              " 'distributions',\n",
              " 'diverging_palette',\n",
              " 'dogplot',\n",
              " 'ecdfplot',\n",
              " 'external',\n",
              " 'get_data_home',\n",
              " 'get_dataset_names',\n",
              " 'heatmap',\n",
              " 'histplot',\n",
              " 'hls_palette',\n",
              " 'husl_palette',\n",
              " 'jointplot',\n",
              " 'kdeplot',\n",
              " 'light_palette',\n",
              " 'lineplot',\n",
              " 'lmplot',\n",
              " 'load_dataset',\n",
              " 'matrix',\n",
              " 'miscplot',\n",
              " 'move_legend',\n",
              " 'mpl',\n",
              " 'mpl_palette',\n",
              " 'pairplot',\n",
              " 'palettes',\n",
              " 'palplot',\n",
              " 'plotting_context',\n",
              " 'pointplot',\n",
              " 'rcmod',\n",
              " 'regplot',\n",
              " 'regression',\n",
              " 'relational',\n",
              " 'relplot',\n",
              " 'reset_defaults',\n",
              " 'reset_orig',\n",
              " 'residplot',\n",
              " 'rugplot',\n",
              " 'saturate',\n",
              " 'scatterplot',\n",
              " 'set',\n",
              " 'set_color_codes',\n",
              " 'set_context',\n",
              " 'set_hls_values',\n",
              " 'set_palette',\n",
              " 'set_style',\n",
              " 'set_theme',\n",
              " 'stripplot',\n",
              " 'swarmplot',\n",
              " 'utils',\n",
              " 'violinplot',\n",
              " 'widgets',\n",
              " 'xkcd_palette',\n",
              " 'xkcd_rgb']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(sns.heatmap)"
      ],
      "metadata": {
        "id": "IT3SBxWEttTj",
        "outputId": "931a5c06-c927-4832-eaa7-feb6123cbbed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function heatmap in module seaborn.matrix:\n",
            "\n",
            "heatmap(data, *, vmin=None, vmax=None, cmap=None, center=None, robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', cbar=True, cbar_kws=None, cbar_ax=None, square=False, xticklabels='auto', yticklabels='auto', mask=None, ax=None, **kwargs)\n",
            "    Plot rectangular data as a color-encoded matrix.\n",
            "    \n",
            "    This is an Axes-level function and will draw the heatmap into the\n",
            "    currently-active Axes if none is provided to the ``ax`` argument.  Part of\n",
            "    this Axes space will be taken and used to plot a colormap, unless ``cbar``\n",
            "    is False or a separate Axes is provided to ``cbar_ax``.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    data : rectangular dataset\n",
            "        2D dataset that can be coerced into an ndarray. If a Pandas DataFrame\n",
            "        is provided, the index/column information will be used to label the\n",
            "        columns and rows.\n",
            "    vmin, vmax : floats, optional\n",
            "        Values to anchor the colormap, otherwise they are inferred from the\n",
            "        data and other keyword arguments.\n",
            "    cmap : matplotlib colormap name or object, or list of colors, optional\n",
            "        The mapping from data values to color space. If not provided, the\n",
            "        default will depend on whether ``center`` is set.\n",
            "    center : float, optional\n",
            "        The value at which to center the colormap when plotting divergent data.\n",
            "        Using this parameter will change the default ``cmap`` if none is\n",
            "        specified.\n",
            "    robust : bool, optional\n",
            "        If True and ``vmin`` or ``vmax`` are absent, the colormap range is\n",
            "        computed with robust quantiles instead of the extreme values.\n",
            "    annot : bool or rectangular dataset, optional\n",
            "        If True, write the data value in each cell. If an array-like with the\n",
            "        same shape as ``data``, then use this to annotate the heatmap instead\n",
            "        of the data. Note that DataFrames will match on position, not index.\n",
            "    fmt : str, optional\n",
            "        String formatting code to use when adding annotations.\n",
            "    annot_kws : dict of key, value mappings, optional\n",
            "        Keyword arguments for :meth:`matplotlib.axes.Axes.text` when ``annot``\n",
            "        is True.\n",
            "    linewidths : float, optional\n",
            "        Width of the lines that will divide each cell.\n",
            "    linecolor : color, optional\n",
            "        Color of the lines that will divide each cell.\n",
            "    cbar : bool, optional\n",
            "        Whether to draw a colorbar.\n",
            "    cbar_kws : dict of key, value mappings, optional\n",
            "        Keyword arguments for :meth:`matplotlib.figure.Figure.colorbar`.\n",
            "    cbar_ax : matplotlib Axes, optional\n",
            "        Axes in which to draw the colorbar, otherwise take space from the\n",
            "        main Axes.\n",
            "    square : bool, optional\n",
            "        If True, set the Axes aspect to \"equal\" so each cell will be\n",
            "        square-shaped.\n",
            "    xticklabels, yticklabels : \"auto\", bool, list-like, or int, optional\n",
            "        If True, plot the column names of the dataframe. If False, don't plot\n",
            "        the column names. If list-like, plot these alternate labels as the\n",
            "        xticklabels. If an integer, use the column names but plot only every\n",
            "        n label. If \"auto\", try to densely plot non-overlapping labels.\n",
            "    mask : bool array or DataFrame, optional\n",
            "        If passed, data will not be shown in cells where ``mask`` is True.\n",
            "        Cells with missing values are automatically masked.\n",
            "    ax : matplotlib Axes, optional\n",
            "        Axes in which to draw the plot, otherwise use the currently-active\n",
            "        Axes.\n",
            "    kwargs : other keyword arguments\n",
            "        All other keyword arguments are passed to\n",
            "        :meth:`matplotlib.axes.Axes.pcolormesh`.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    ax : matplotlib Axes\n",
            "        Axes object with the heatmap.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    clustermap : Plot a matrix using hierarchical clustering to arrange the\n",
            "                 rows and columns.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    \n",
            "    .. include:: ../docstrings/heatmap.rst\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(sns.algorithms)"
      ],
      "metadata": {
        "id": "R1XVIJHEt7qK",
        "outputId": "db5718b8-296a-4c76-b613-d883e1008fd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on module seaborn.algorithms in seaborn:\n",
            "\n",
            "NAME\n",
            "    seaborn.algorithms - Algorithms to support fitting routines in seaborn plotting functions.\n",
            "\n",
            "FUNCTIONS\n",
            "    bootstrap(*args, **kwargs)\n",
            "        Resample one or more arrays with replacement and store aggregate values.\n",
            "        \n",
            "        Positional arguments are a sequence of arrays to bootstrap along the first\n",
            "        axis and pass to a summary function.\n",
            "        \n",
            "        Keyword arguments:\n",
            "            n_boot : int, default=10000\n",
            "                Number of iterations\n",
            "            axis : int, default=None\n",
            "                Will pass axis to ``func`` as a keyword argument.\n",
            "            units : array, default=None\n",
            "                Array of sampling unit IDs. When used the bootstrap resamples units\n",
            "                and then observations within units instead of individual\n",
            "                datapoints.\n",
            "            func : string or callable, default=\"mean\"\n",
            "                Function to call on the args that are passed in. If string, uses as\n",
            "                name of function in the numpy namespace. If nans are present in the\n",
            "                data, will try to use nan-aware version of named function.\n",
            "            seed : Generator | SeedSequence | RandomState | int | None\n",
            "                Seed for the random number generator; useful if you want\n",
            "                reproducible resamples.\n",
            "        \n",
            "        Returns\n",
            "        -------\n",
            "        boot_dist: array\n",
            "            array of bootstrapped statistic values\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.11/dist-packages/seaborn/algorithms.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Click to see solution\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load time-series DF/F data\n",
        "df = pd.read_csv(\"population_timeseries.csv\")\n",
        "\n",
        "# Parameters\n",
        "stim_onset = 30        # Frame when stimulus starts\n",
        "window = 10            # 10 time points after onset = ~1 sec if 10 Hz sampling\n",
        "\n",
        "# Step 1: Extract post-stimulus window\n",
        "post_stim = df[(df[\"time\"] >= stim_onset) & (df[\"time\"] < stim_onset + window)]\n",
        "\n",
        "# Step 2: Compute mean DF/F per neuron per trial\n",
        "# Group the post-stimulus data by trial, stimulus, and neuron\n",
        "grouped_dff = post_stim.groupby([\"trial\", \"stimulus\", \"neuron\"])\n",
        "\n",
        "# Compute the average DF/F for each group\n",
        "mean_dff = grouped_dff[\"dff\"].mean().reset_index()\n",
        "\n",
        "# Step 3: Pivot to get population vectors: rows = trials, cols = neurons\n",
        "population_df = mean_dff.pivot_table(index=[\"trial\", \"stimulus\"], columns=\"neuron\", values=\"dff\")\n",
        "\n",
        "# Step 4: Compute pairwise cosine distances (angle-based similarity)\n",
        "cosine_dist = pairwise_distances(population_df, metric='cosine')\n",
        "\n",
        "# Step 5: Plot distance matrix as heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cosine_dist, xticklabels=False, yticklabels=False, cmap='viridis')\n",
        "plt.title(\"Pairwise Cosine Distances Between Population Vectors (Trials)\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.ylabel(\"Trial\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qKStjjPxM20L",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üß† Questions for Discussion**\n",
        "\n",
        "- What does a low cosine distance between two trials mean?\n",
        "- What patterns do you see in the heatmap ‚Äî do trials from the same stimulus group together (i.e., show lower pairwise distances)?\n",
        "- What does this suggest about how population activity encodes stimuli?\n",
        "- Why might comparing population patterns be more informative than just averaging ŒîF/F per neuron?\n",
        "- What are other ways to measure similarity or structure in population responses beyond cosine distance?"
      ],
      "metadata": {
        "id": "Pl5f-SXUe59B"
      }
    }
  ]
}